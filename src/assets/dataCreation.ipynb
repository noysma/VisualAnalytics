{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'Visual Analytics/VAST-Challenge-2022/VA - Datasets/Activity Logs'\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Loading the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Adding the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Union of all DataFrames in the list into a single DataFrame\n",
    "merged_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 113923735 entries, 0 to 113923734\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   timestamp          object \n",
      " 1   currentLocation    object \n",
      " 2   participantId      float64\n",
      " 3   currentMode        object \n",
      " 4   hungerStatus       object \n",
      " 5   sleepStatus        object \n",
      " 6   apartmentId        float64\n",
      " 7   availableBalance   float64\n",
      " 8   jobId              float64\n",
      " 9   financialStatus    object \n",
      " 10  dailyFoodBudget    float64\n",
      " 11  weeklyExtraBudget  float64\n",
      "dtypes: float64(6), object(6)\n",
      "memory usage: 10.2+ GB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday    81553526\n",
       "Weekend    32370209\n",
       "Name: weekday, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['timestamp'] = pd.to_datetime(merged_df['timestamp'])\n",
    "\n",
    "merged_df['weekday'] = merged_df['timestamp'].dt.day_name()\n",
    "\n",
    "merged_df['weekday'] = merged_df['weekday'].replace(['Monday','Tuesday','Wednesday','Thursday','Friday'],'Weekday')\n",
    "\n",
    "merged_df['weekday'] = merged_df['weekday'].replace(['Saturday','Sunday'],'Weekend')\n",
    "\n",
    "merged_df['weekday'].value_counts()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week and week-end days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = pd.read_csv(\"Visual Analytics/VAST-Challenge-2022/VA - Datasets/CheckinJournal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp conversion\n",
    "check_df['timestamp'] = pd.to_datetime(check_df['timestamp'])\n",
    "merged_df['timestamp'] = pd.to_datetime(check_df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(merged_df, check_df, on=['participantId', 'timestamp'], how='inner')\n",
    "\n",
    "# Count of participantId in the currentLocation in a given timestamp\n",
    "result_df = final.groupby(['timestamp', 'currentLocation']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column where 'weekend' if the day is Saturday or Sunday and 'weekday' otherwise\n",
    "result_df['weekday'] = result_df['timestamp'].dt.day_name()\n",
    "\n",
    "result_df['weekday'] = result_df['weekday'].replace(['Monday','Tuesday','Wednesday','Thursday','Friday'],'Weekday')\n",
    "result_df['weekday'] = result_df['weekday'].replace(['Saturday','Sunday'],'Weekend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of people at a given weekday location\n",
    "count_feriali = result_df[result_df['weekday'] == 'Weekday'].groupby('currentLocation')['count'].sum().reset_index()\n",
    "# Count of people at a given weekend location\n",
    "count_festivi = result_df[result_df['weekday'] == 'Weekend'].groupby('currentLocation')['count'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_feriali.to_csv('public/weekdays.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_festivi.to_csv('public/weekends.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Visual Analytics/VAST-Challenge-2022/VA - Datasets/TravelJournal.csv\")\n",
    "travel = df[['travelEndTime', 'travelStartTime']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel = travel.sort_values(by=['travelStartTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel['travelEndTime'] = pd.to_datetime(travel['travelEndTime'])\n",
    "travel['travelStartTime'] = pd.to_datetime(travel['travelStartTime'])\n",
    "travel['travelDuration'] = travel['travelEndTime'] - travel['travelStartTime']\n",
    "travel['travelDuration'] = travel['travelDuration'].dt.total_seconds().div(60).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = travel.groupby(travel['travelStartTime'].dt.date)['travelDuration'].sum().reset_index()\n",
    "\n",
    "# Rename'travelStartTime' into 'date'\n",
    "df_new = df_new.rename(columns={'travelStartTime': 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('public/travelDuration.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(seq1, seq2):\n",
    "    return sum(el1 != el2 for el1, el2 in zip(seq1, seq2))\n",
    "\n",
    "def find_similar_participants(grouped_df):\n",
    "    min_distance = float('inf')\n",
    "    max_distance = 0\n",
    "    most_similar_participants = ()\n",
    "    least_similar_participants = ()\n",
    "\n",
    "    for i in range(len(grouped_df)):\n",
    "        for j in range(i + 1, len(grouped_df)):\n",
    "            seq1 = grouped_df['currentMode'].iloc[i]\n",
    "            seq2 = grouped_df['currentMode'].iloc[j]\n",
    "\n",
    "            distance = hamming_distance(seq1, seq2)\n",
    "            \n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                most_similar_participants = (grouped_df['participantId'].iloc[i], grouped_df['participantId'].iloc[j])\n",
    "                \n",
    "            if distance > max_distance:\n",
    "                max_distance = distance\n",
    "                least_similar_participants = (grouped_df['participantId'].iloc[i], grouped_df['participantId'].iloc[j])\n",
    "\n",
    "    return most_similar_participants, least_similar_participants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar, least_similar = find_similar_participants(merged_df)\n",
    "print(\"Partecipanti pi√π simili:\", most_similar)\n",
    "print(\"Partecipanti meno simili:\", least_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routine = merged_df[['participantId', 'timestamp', 'currentMode']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "routine.to_csv('public/routine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_routine = pd.read_csv('public/routine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_routine_179 = df_routine[df_routine['participantId'] == 179]\n",
    "df_routine_728 = df_routine[df_routine['participantId'] == 728]\n",
    "df_routine_902 = df_routine[df_routine['participantId'] == 902]\n",
    "df_routine_911 = df_routine[df_routine['participantId'] == 911]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_routine_179.to_csv('public/routine_179.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_routine_902.to_csv('public/routine_902.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_routine_728.to_csv('public/routine_728.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_routine_911.to_csv('public/routine_911.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Visual Analytics/VAST-Challenge-2022/VA - Datasets/Jobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partecipants = merged_df[['jobId','participantId','timestamp']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover = df[['jobId','hourlyRate']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounds hourlyRate to 2 decimal places\n",
    "turnover['hourlyRate'] = turnover['hourlyRate'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn = pd.merge(partecipants, turnover, on='jobId')\n",
    "tover = turn[['jobId','participantId','hourlyRate']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where participanId and jobId are the same, take only the first line\n",
    "tover = df.drop_duplicates(subset=['participantId', 'jobId'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminates the last occurrence of each participantId\n",
    "last_occurrences = tover.drop_duplicates(subset=['participantId'], keep='last').index\n",
    "over = tover.drop(last_occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = over.groupby(['jobId', 'hourlyRate']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('public/turnover.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
